---
title: '[빅데이터] (실습) 하둡 스파크 ' 
excerpt: '하둡 YARN에서 스파크 설치 & 스파크 실행 및 동작 확인'
categories:
    - Big Data

tag:
    - BigData
    - hadoop
    - spark

author_profile: true    #작성자 프로필 출력 여부

last_modified_at: 2020-05-16T23:00:00+09:00

toc: true   #Table Of Contents 목차 

toc_sticky: true
---

## Intro
빅데이터 강의 시간의 스파크 실습 내용을 정리한 것입니다.
실습 환경 준비

## 스파크의 실행 동작 모드

### 스파크 다운로드 및 압축 해제

마스터 노드에서 설치 한 후, 슬레이브 노드에 복사할 예정입니다. 
먼저 마스터 노드에서 설치하고 압축 해제하는 과정입니다. 

```
$ wget http://mirror.apache-kr.org/spark/spark-2.4.5/spark-2.4.5-bin-hadoop2.7.tgz

$ tar –xvzf spark-2.4.5-bin-hadoop2.7.tgz
```

![p1](https://user-images.githubusercontent.com/47733530/82431217-5bf35880-9ac9-11ea-925c-9506b16a6b4d.png)

![p2](https://user-images.githubusercontent.com/47733530/82431226-5d248580-9ac9-11ea-852a-9c473bfc34e8.png)

<br>

### 환경 변수 설정
아래 사진과 같이 하둡 환경 변수를 설정하여 줍니다.

```
$ sudo nano ~/.bashrc
```

![p3](https://user-images.githubusercontent.com/47733530/82431274-6b72a180-9ac9-11ea-96dd-b4c33631be64.png)

환경 변수 추가 후 아래 명령어를 통해 적용합니다. source[환경 설정 파일명] 명령은 리부팅이나 쉘에 재로그인 하지 않고 수정된 새로운 환경 설정 내용을 즉시 적용하기 위해서 사용합니다. 

```
$ source ~/.bashrc
```

![p4](https://user-images.githubusercontent.com/47733530/82431282-6c0b3800-9ac9-11ea-8b8a-21db3b4b7eb5.png)

<br>

### 스파크 설정

__설정 파일 복사__

기존 스파크 설정 파일들을 복사한 후, 변경 해줍니다. 경로는 ~/spark-2.4.5-bin-hadoop2.7/conf/ 입니다. template파일들을 각각 복사하여 기존의 default 설정을 사용하면서 일부만 수정해서 설정해줍니다. 경로는 ~/spark-2.4.5-bin-hadoop2.7/conf/


```
$ cp slaves.template slaves
$ cp spark-defaults.conf.template spark-defaults.conf
$ cp spark-env.sh.template spark-env.sh
```

![p5](https://user-images.githubusercontent.com/47733530/82431378-88a77000-9ac9-11ea-859a-0508f60ac828.png)

저는 WinSCP를 사용하여 스파크 환경 변수를 설정하여주었습니다. 경로는 ~/spark-2.4.5-bin-hadoop2.7/conf/spark-env 입니다. 스파크 워커 메모리를 2g로 설정하고 빌트인 해주었습니다.

![p6](https://user-images.githubusercontent.com/47733530/82431389-8a713380-9ac9-11ea-98c8-270be085e517.png)

![p7](https://user-images.githubusercontent.com/47733530/82431393-8a713380-9ac9-11ea-8c28-0c981e0868f5.png)

경로는 ~/spark-2.4.5-bin-hadoop2.7/conf/spark-defaults.conf 이며, jar/spark-jars/*.jar 를 추가하였습ㅂ니다. 

![p8](https://user-images.githubusercontent.com/47733530/82431395-8b09ca00-9ac9-11ea-8597-83ab544f7085.png)

~/spark-2.4.5-bin-hadoop2.7/conf/slaves에서 스파크 슬레이브를 설정하였습니다.

![p9](https://user-images.githubusercontent.com/47733530/82431396-8b09ca00-9ac9-11ea-97be-0f6823cdfcee.png)

하둡을 실행하고 다운 받은 모든 스파크의 jar 파일을 하둡 파일 시스템으로 적재 해줍니다. 이는 --master yarn 모드 실행을 위한 작업입니다. start-all.sh 명령으로 하둡을 실행시키고 잘 실행 되었는지 jps 명령으로 확인해 주었습니다.

```
$ start-all.sh
$ jps
$ hadoop fs -mkdir /jar
$ hadoop -mkdir /jar/spark-jars
$ hadoop fs -put $SPARK_HOME/jar/* /jar/spark-jars/
```

![p10](https://user-images.githubusercontent.com/47733530/82431398-8ba26080-9ac9-11ea-9bdb-425a8dc0bd5b.png)

![p11](https://user-images.githubusercontent.com/47733530/82431399-8ba26080-9ac9-11ea-986d-1b72b2d5297b.png)

그 후, 네임노드 웹(192.168.0.1:50070)에 접속하여 파일 복사를 확인합니다.

![p12](https://user-images.githubusercontent.com/47733530/82431400-8c3af700-9ac9-11ea-8885-3402e4c9a2b9.png)

각 서버로 스파크 설치 디렉토리를 배포하고, scp 명령어로 .bashrc 파일을 slave1에 복사합니다. 설치한 스파크의 모든 내용을 slave1에 복사합니다.

```
$ scp .bashrc slave1:~/
$ scp -r ~/spark-2.4.5-bin-hadoop2.7 slave1:~/
```

![p13](https://user-images.githubusercontent.com/47733530/82431495-ad034c80-9ac9-11ea-87d5-925e8ef520bf.png)

<br>

### 스파크 실행 및 동작 확인

master에서 스파크를 실행시키고 jps 명령어로 master와 slave1에서의 하둡과 스파크의 실행을 확인 합니다. 아래 화면과 같이 출력되면 잘 실행 되고 있는 것 입니다.

```
$ $SPARK_HOME/sbin/start-all.sh
$ jps
```

![p14](https://user-images.githubusercontent.com/47733530/82431504-b096d380-9ac9-11ea-8cfb-e3080e01a77e.png)

![p15](https://user-images.githubusercontent.com/47733530/82431508-b12f6a00-9ac9-11ea-9370-cac4f88a1638.png)

스파크 마스터 포트 웹(192.168.0.1:8080)으로 접속 확인 합니다.

![p16](https://user-images.githubusercontent.com/47733530/82431593-cc9a7500-9ac9-11ea-81d1-ef354b8e247c.png)

<br>

## 스파크 쉘(Spark shell)
### 스파크 쉘 실행

yarn 환경에서 스파크 쉘을 실행시킵니다. 쉘이 시작하면서 스파크 세션 객체가 초기화 되고, 변수 spark가 이를 가리킴니다. spark 변수를 이용해 프로그래밍 합니다.

```
$ $SPARK_HOME/bin/spark-shell --master yarn
```

![p17](https://user-images.githubusercontent.com/47733530/82431648-dfad4500-9ac9-11ea-8d40-33d8bf72f6b4.png)

![p18](https://user-images.githubusercontent.com/47733530/82431652-e0de7200-9ac9-11ea-9015-9acb2755302b.png)

Yarn Web(192.168.0.1:8088)에서 스파크 쉘을 확인을 합니다.

![p19](https://user-images.githubusercontent.com/47733530/82431655-e1770880-9ac9-11ea-9bb3-9fdf4d985b43.png)

실습이 끝나면 꼭 spark를 종료하고 하둡을 종료 해주어야 합니다.

```
$ $SPARK_HOME/sbin/stop-all.sh
$ stop-all.sh
```

![p20](https://user-images.githubusercontent.com/47733530/82431656-e20f9f00-9ac9-11ea-96a7-ba6f0d0b6e87.png)

<br>

## 참고 자료
> 빅데이터 수업자료_아파치 스파크 소개